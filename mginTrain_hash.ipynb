{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel, LabeledPoint, RandomForest\n",
    "\n",
    "app_name = \"w261_final_training\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawRDD = spark.read.csv(\"data/sample.txt\", header=False, sep=\"\\t\").rdd\n",
    "dataRDD = rawRDD.map(lambda row: ([None if el is None else int(el) for el in row[1:14]] + list(row[14:]), int(row[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data we saved from the EDA. This helps us engineer the features and configure the model\n",
    "\n",
    "frequent_feats = {}\n",
    "\n",
    "with open(\"data/freq_category_counts.csv\") as csvfile:\n",
    "    for row in csv.DictReader(csvfile):\n",
    "        total = int(row[\"total\"])\n",
    "        if total >= 10:\n",
    "            key = \"{}-{}\".format(row[\"col_name\"], row[\"category\"])\n",
    "            frequent_feats[key] = int(row[\"category_id\"])\n",
    "\n",
    "with open(\"data/num_significant_categories.csv\") as csvfile:\n",
    "    num_significant_categories = { row[\"field\"]: int(row[\"count\"]) for row in csv.DictReader(csvfile) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a row of features and the label\n",
    "# leave features 0-13 the same (already integers), covert and hash features \n",
    "def hashTrick(features, label, N):\n",
    "    newFeatures = list(features[0:13])\n",
    "    for i in range(14, len(features)):\n",
    "        if features[i] == None:\n",
    "            newFeatures += list([None])\n",
    "        else:\n",
    "            newFeatures += list([int(features[i], 16) % 2**N])\n",
    "    yield (newFeatures, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRDD = dataRDD.flatMap(lambda r: hashTrick(r[0], r[1], 16)).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles of Trees\n",
    "\n",
    "The numerical columns are pretty much used directly. Note that NULLs are encoded with the value -10 (also tried 0 and imputing with the medians). Categorical values are kept if they are in the common categories from the EDA. They were assigned an integer ID, which is in the frequent_feats dict. This is used to encode each value. All rare values are converted to a special ID. NULLs are converted to yet another special ID. Note that this adds 2 additional categories from the ones we picked from the EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labeled(pair):\n",
    "    \"\"\"transform input data into the features\"\"\"\n",
    "    row, label = pair\n",
    "    # collect the converted values here\n",
    "    vector = []\n",
    "    \n",
    "    for i, val in enumerate(row):\n",
    "        # if this is an numerical column\n",
    "        if i < 13:\n",
    "            if val is None:\n",
    "                val = -10\n",
    "        # if this is categorical\n",
    "        else:\n",
    "            if val is not None:\n",
    "                key = \"C{}-{}\".format(i - 13, val)\n",
    "                # if its one of our \"common\" values\n",
    "                if key in frequent_feats:\n",
    "                    # look up its ID\n",
    "                    val = frequent_feats[key]\n",
    "                else:\n",
    "                    # give it the special value for RARE\n",
    "                    val = num_significant_categories[\"C\" + str(i - 13)]\n",
    "            else:\n",
    "                # give it the special value for NULL\n",
    "                val = num_significant_categories[\"C\" + str(i - 13)] + 1\n",
    "        vector.append(val)\n",
    "    return LabeledPoint(label, vector)\n",
    "\n",
    "def resample(pair):\n",
    "    \"\"\"sample the positive examples twice to increase their importance\"\"\"\n",
    "    if pair.label == 1:\n",
    "        return [pair, pair]\n",
    "    else:\n",
    "        return [pair]\n",
    "\n",
    "labeledRDD = dataRDD.map(to_labeled)\n",
    "\n",
    "# set model params\n",
    "categoricalFeaturesInfo = { int(feat[1:]) + 13: count + 2 for feat, count in num_significant_categories.items() }\n",
    "maxBins = max(num_significant_categories.values()) + 2\n",
    "trainingData, validationData = labeledRDD.randomSplit([0.9, 0.1])\n",
    "# re-samples the positive class\n",
    "#trainingData = trainingData.flatMap(resample)\n",
    "\n",
    "labels = validationData.map(lambda lp: lp.label).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGBT(trainingData, maxBins, maxDepth, numIterations):\n",
    "\n",
    "    model_gbdt = GradientBoostedTrees.trainClassifier(trainingData,\n",
    "                                                      categoricalFeaturesInfo={},\n",
    "                                                      maxBins=maxBins,\n",
    "                                                      maxDepth=8,\n",
    "                                                      numIterations=10) # how many trees\n",
    "\n",
    "    # Evaluate model on test instances and compute validation accuracy\n",
    "    predictions_gbdt = model_gbdt.predict(validationData.map(lambda x: x.features))\n",
    "    #labelsAndPredictions = validationData.map(lambda lp: lp.label).zip(predictions)\n",
    "    #testErr = labelsAndPredictions.filter(lambda lp: lp[0] != lp[1]).count() / float(validationData.count())\n",
    "\n",
    "    preds_gbdt = predictions_gbdt.collect()\n",
    "    accuracy_gbdt = np.mean(np.array(labels) == np.array(preds_gbdt))\n",
    "    print('accuracy = ' + str(accuracy_gbdt))\n",
    "\n",
    "    model_name = \"models/gbdt-model\"\n",
    "    # save the model\n",
    "    !rm -rf /media/notebooks/{model_name}\n",
    "    model_gbdt.save(sc, model_name)\n",
    "\n",
    "    # how to load the model again, tho not necessary in this file\n",
    "    #sameModel = GradientBoostedTreesModel.load(sc, model_name)\n",
    "    #print(sameModel.toDebugString())\n",
    "    \n",
    "    return (labels, preds_gbdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth = 3, Max Bins = 10, Iterations = 5\n",
      "accuracy = 0.7691511387163561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.49      0.26      0.34       221\n",
      "\n",
      "avg / total       0.73      0.77      0.74       966\n",
      "\n",
      "[[686  59]\n",
      " [164  57]]\n",
      "\n",
      "Depth = 3, Max Bins = 10, Iterations = 9\n",
      "accuracy = 0.7691511387163561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.49      0.26      0.34       221\n",
      "\n",
      "avg / total       0.73      0.77      0.74       966\n",
      "\n",
      "[[686  59]\n",
      " [164  57]]\n",
      "\n",
      "Depth = 3, Max Bins = 15, Iterations = 5\n",
      "accuracy = 0.7484472049689441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.38      0.15      0.22       221\n",
      "\n",
      "avg / total       0.69      0.75      0.71       966\n",
      "\n",
      "[[689  56]\n",
      " [187  34]]\n",
      "\n",
      "Depth = 3, Max Bins = 15, Iterations = 9\n",
      "accuracy = 0.7484472049689441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.38      0.15      0.22       221\n",
      "\n",
      "avg / total       0.69      0.75      0.71       966\n",
      "\n",
      "[[689  56]\n",
      " [187  34]]\n",
      "\n",
      "Depth = 3, Max Bins = 20, Iterations = 5\n",
      "accuracy = 0.7536231884057971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.42      0.19      0.26       221\n",
      "\n",
      "avg / total       0.71      0.75      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [179  42]]\n",
      "\n",
      "Depth = 3, Max Bins = 20, Iterations = 9\n",
      "accuracy = 0.7536231884057971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.42      0.19      0.26       221\n",
      "\n",
      "avg / total       0.71      0.75      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [179  42]]\n",
      "\n",
      "Depth = 3, Max Bins = 25, Iterations = 5\n",
      "accuracy = 0.7732919254658385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.51      0.26      0.35       221\n",
      "\n",
      "avg / total       0.74      0.77      0.74       966\n",
      "\n",
      "[[689  56]\n",
      " [163  58]]\n",
      "\n",
      "Depth = 3, Max Bins = 25, Iterations = 9\n",
      "accuracy = 0.7732919254658385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.51      0.26      0.35       221\n",
      "\n",
      "avg / total       0.74      0.77      0.74       966\n",
      "\n",
      "[[689  56]\n",
      " [163  58]]\n",
      "\n",
      "Depth = 3, Max Bins = 30, Iterations = 5\n",
      "accuracy = 0.7463768115942029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.85       745\n",
      "        1.0       0.40      0.21      0.27       221\n",
      "\n",
      "avg / total       0.70      0.75      0.72       966\n",
      "\n",
      "[[675  70]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 3, Max Bins = 30, Iterations = 9\n",
      "accuracy = 0.7463768115942029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.85       745\n",
      "        1.0       0.40      0.21      0.27       221\n",
      "\n",
      "avg / total       0.70      0.75      0.72       966\n",
      "\n",
      "[[675  70]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 3, Max Bins = 35, Iterations = 5\n",
      "accuracy = 0.7567287784679089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.22      0.29       221\n",
      "\n",
      "avg / total       0.72      0.76      0.72       966\n",
      "\n",
      "[[683  62]\n",
      " [173  48]]\n",
      "\n",
      "Depth = 3, Max Bins = 35, Iterations = 9\n",
      "accuracy = 0.7567287784679089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.22      0.29       221\n",
      "\n",
      "avg / total       0.72      0.76      0.72       966\n",
      "\n",
      "[[683  62]\n",
      " [173  48]]\n",
      "\n",
      "Depth = 3, Max Bins = 40, Iterations = 5\n",
      "accuracy = 0.7556935817805382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.43      0.20      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[685  60]\n",
      " [176  45]]\n",
      "\n",
      "Depth = 3, Max Bins = 40, Iterations = 9\n",
      "accuracy = 0.7556935817805382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.43      0.20      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[685  60]\n",
      " [176  45]]\n",
      "\n",
      "Depth = 3, Max Bins = 45, Iterations = 5\n",
      "accuracy = 0.7598343685300207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       745\n",
      "        1.0       0.44      0.19      0.27       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[691  54]\n",
      " [178  43]]\n",
      "\n",
      "Depth = 3, Max Bins = 45, Iterations = 9\n",
      "accuracy = 0.7598343685300207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       745\n",
      "        1.0       0.44      0.19      0.27       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[691  54]\n",
      " [178  43]]\n",
      "\n",
      "Depth = 3, Max Bins = 50, Iterations = 5\n",
      "accuracy = 0.7577639751552795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.21      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 3, Max Bins = 50, Iterations = 9\n",
      "accuracy = 0.7577639751552795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.21      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 6, Max Bins = 10, Iterations = 5\n",
      "accuracy = 0.7691511387163561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.49      0.26      0.34       221\n",
      "\n",
      "avg / total       0.73      0.77      0.74       966\n",
      "\n",
      "[[686  59]\n",
      " [164  57]]\n",
      "\n",
      "Depth = 6, Max Bins = 10, Iterations = 9\n",
      "accuracy = 0.7691511387163561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.49      0.26      0.34       221\n",
      "\n",
      "avg / total       0.73      0.77      0.74       966\n",
      "\n",
      "[[686  59]\n",
      " [164  57]]\n",
      "\n",
      "Depth = 6, Max Bins = 15, Iterations = 5\n",
      "accuracy = 0.7484472049689441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.38      0.15      0.22       221\n",
      "\n",
      "avg / total       0.69      0.75      0.71       966\n",
      "\n",
      "[[689  56]\n",
      " [187  34]]\n",
      "\n",
      "Depth = 6, Max Bins = 15, Iterations = 9\n",
      "accuracy = 0.7484472049689441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.38      0.15      0.22       221\n",
      "\n",
      "avg / total       0.69      0.75      0.71       966\n",
      "\n",
      "[[689  56]\n",
      " [187  34]]\n",
      "\n",
      "Depth = 6, Max Bins = 20, Iterations = 5\n",
      "accuracy = 0.7536231884057971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.42      0.19      0.26       221\n",
      "\n",
      "avg / total       0.71      0.75      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [179  42]]\n",
      "\n",
      "Depth = 6, Max Bins = 20, Iterations = 9\n",
      "accuracy = 0.7536231884057971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.42      0.19      0.26       221\n",
      "\n",
      "avg / total       0.71      0.75      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [179  42]]\n",
      "\n",
      "Depth = 6, Max Bins = 25, Iterations = 5\n",
      "accuracy = 0.7732919254658385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.51      0.26      0.35       221\n",
      "\n",
      "avg / total       0.74      0.77      0.74       966\n",
      "\n",
      "[[689  56]\n",
      " [163  58]]\n",
      "\n",
      "Depth = 6, Max Bins = 25, Iterations = 9\n",
      "accuracy = 0.7732919254658385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.51      0.26      0.35       221\n",
      "\n",
      "avg / total       0.74      0.77      0.74       966\n",
      "\n",
      "[[689  56]\n",
      " [163  58]]\n",
      "\n",
      "Depth = 6, Max Bins = 30, Iterations = 5\n",
      "accuracy = 0.7463768115942029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.85       745\n",
      "        1.0       0.40      0.21      0.27       221\n",
      "\n",
      "avg / total       0.70      0.75      0.72       966\n",
      "\n",
      "[[675  70]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 6, Max Bins = 30, Iterations = 9\n",
      "accuracy = 0.7463768115942029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.85       745\n",
      "        1.0       0.40      0.21      0.27       221\n",
      "\n",
      "avg / total       0.70      0.75      0.72       966\n",
      "\n",
      "[[675  70]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 6, Max Bins = 35, Iterations = 5\n",
      "accuracy = 0.7567287784679089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.22      0.29       221\n",
      "\n",
      "avg / total       0.72      0.76      0.72       966\n",
      "\n",
      "[[683  62]\n",
      " [173  48]]\n",
      "\n",
      "Depth = 6, Max Bins = 35, Iterations = 9\n",
      "accuracy = 0.7567287784679089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.22      0.29       221\n",
      "\n",
      "avg / total       0.72      0.76      0.72       966\n",
      "\n",
      "[[683  62]\n",
      " [173  48]]\n",
      "\n",
      "Depth = 6, Max Bins = 40, Iterations = 5\n",
      "accuracy = 0.7556935817805382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.43      0.20      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[685  60]\n",
      " [176  45]]\n",
      "\n",
      "Depth = 6, Max Bins = 40, Iterations = 9\n",
      "accuracy = 0.7556935817805382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.43      0.20      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[685  60]\n",
      " [176  45]]\n",
      "\n",
      "Depth = 6, Max Bins = 45, Iterations = 5\n",
      "accuracy = 0.7598343685300207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       745\n",
      "        1.0       0.44      0.19      0.27       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[691  54]\n",
      " [178  43]]\n",
      "\n",
      "Depth = 6, Max Bins = 45, Iterations = 9\n",
      "accuracy = 0.7598343685300207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       745\n",
      "        1.0       0.44      0.19      0.27       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[691  54]\n",
      " [178  43]]\n",
      "\n",
      "Depth = 6, Max Bins = 50, Iterations = 5\n",
      "accuracy = 0.7577639751552795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.21      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 6, Max Bins = 50, Iterations = 9\n",
      "accuracy = 0.7577639751552795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.21      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 9, Max Bins = 10, Iterations = 5\n",
      "accuracy = 0.7691511387163561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.49      0.26      0.34       221\n",
      "\n",
      "avg / total       0.73      0.77      0.74       966\n",
      "\n",
      "[[686  59]\n",
      " [164  57]]\n",
      "\n",
      "Depth = 9, Max Bins = 10, Iterations = 9\n",
      "accuracy = 0.7691511387163561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.49      0.26      0.34       221\n",
      "\n",
      "avg / total       0.73      0.77      0.74       966\n",
      "\n",
      "[[686  59]\n",
      " [164  57]]\n",
      "\n",
      "Depth = 9, Max Bins = 15, Iterations = 5\n",
      "accuracy = 0.7484472049689441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.38      0.15      0.22       221\n",
      "\n",
      "avg / total       0.69      0.75      0.71       966\n",
      "\n",
      "[[689  56]\n",
      " [187  34]]\n",
      "\n",
      "Depth = 9, Max Bins = 15, Iterations = 9\n",
      "accuracy = 0.7484472049689441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.38      0.15      0.22       221\n",
      "\n",
      "avg / total       0.69      0.75      0.71       966\n",
      "\n",
      "[[689  56]\n",
      " [187  34]]\n",
      "\n",
      "Depth = 9, Max Bins = 20, Iterations = 5\n",
      "accuracy = 0.7536231884057971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.42      0.19      0.26       221\n",
      "\n",
      "avg / total       0.71      0.75      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [179  42]]\n",
      "\n",
      "Depth = 9, Max Bins = 20, Iterations = 9\n",
      "accuracy = 0.7536231884057971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.42      0.19      0.26       221\n",
      "\n",
      "avg / total       0.71      0.75      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [179  42]]\n",
      "\n",
      "Depth = 9, Max Bins = 25, Iterations = 5\n",
      "accuracy = 0.7732919254658385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.51      0.26      0.35       221\n",
      "\n",
      "avg / total       0.74      0.77      0.74       966\n",
      "\n",
      "[[689  56]\n",
      " [163  58]]\n",
      "\n",
      "Depth = 9, Max Bins = 25, Iterations = 9\n",
      "accuracy = 0.7732919254658385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.51      0.26      0.35       221\n",
      "\n",
      "avg / total       0.74      0.77      0.74       966\n",
      "\n",
      "[[689  56]\n",
      " [163  58]]\n",
      "\n",
      "Depth = 9, Max Bins = 30, Iterations = 5\n",
      "accuracy = 0.7463768115942029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.85       745\n",
      "        1.0       0.40      0.21      0.27       221\n",
      "\n",
      "avg / total       0.70      0.75      0.72       966\n",
      "\n",
      "[[675  70]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 9, Max Bins = 30, Iterations = 9\n",
      "accuracy = 0.7463768115942029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.85       745\n",
      "        1.0       0.40      0.21      0.27       221\n",
      "\n",
      "avg / total       0.70      0.75      0.72       966\n",
      "\n",
      "[[675  70]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 9, Max Bins = 35, Iterations = 5\n",
      "accuracy = 0.7567287784679089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.22      0.29       221\n",
      "\n",
      "avg / total       0.72      0.76      0.72       966\n",
      "\n",
      "[[683  62]\n",
      " [173  48]]\n",
      "\n",
      "Depth = 9, Max Bins = 35, Iterations = 9\n",
      "accuracy = 0.7567287784679089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.22      0.29       221\n",
      "\n",
      "avg / total       0.72      0.76      0.72       966\n",
      "\n",
      "[[683  62]\n",
      " [173  48]]\n",
      "\n",
      "Depth = 9, Max Bins = 40, Iterations = 5\n",
      "accuracy = 0.7556935817805382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.43      0.20      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[685  60]\n",
      " [176  45]]\n",
      "\n",
      "Depth = 9, Max Bins = 40, Iterations = 9\n",
      "accuracy = 0.7556935817805382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.43      0.20      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[685  60]\n",
      " [176  45]]\n",
      "\n",
      "Depth = 9, Max Bins = 45, Iterations = 5\n",
      "accuracy = 0.7598343685300207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       745\n",
      "        1.0       0.44      0.19      0.27       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[691  54]\n",
      " [178  43]]\n",
      "\n",
      "Depth = 9, Max Bins = 45, Iterations = 9\n",
      "accuracy = 0.7598343685300207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       745\n",
      "        1.0       0.44      0.19      0.27       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[691  54]\n",
      " [178  43]]\n",
      "\n",
      "Depth = 9, Max Bins = 50, Iterations = 5\n",
      "accuracy = 0.7577639751552795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.21      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 9, Max Bins = 50, Iterations = 9\n",
      "accuracy = 0.7577639751552795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.21      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [175  46]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loop through various combinations of tree depth, bins, and iterations\n",
    "# this will help us hone in on which parameters to use for our final model\n",
    "for td in range(3,12,3):\n",
    "    for b in range(10, maxBins,5):\n",
    "        for i in range(5,12,4):\n",
    "            print(\"Depth = \" + str(td) + \", Max Bins = \" + str(b) + \", Iterations = \" + str(i))\n",
    "            (labels, preds_gbdt) = trainGBT(trainingData, b, td, i)\n",
    "            print(classification_report(labels, preds_gbdt))\n",
    "            print(confusion_matrix(labels, preds_gbdt))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainRF(trainingData, maxBins, numClasses, maxDepth, numTrees):\n",
    "    model_rf = RandomForest.trainClassifier(trainingData,\n",
    "                                        categoricalFeaturesInfo={},\n",
    "                                        maxBins=maxBins,\n",
    "                                        numClasses=numClasses,\n",
    "                                        maxDepth=maxDepth,\n",
    "                                        numTrees=numTrees)\n",
    "\n",
    "    # Evaluate model on test instances and compute validation accuracy\n",
    "    predictions_rf = model_rf.predict(validationData.map(lambda x: x.features))\n",
    "\n",
    "    preds_rf = predictions_rf.collect()\n",
    "    accuracy_rf = np.mean(np.array(labels) == np.array(preds_rf))\n",
    "    print('accuracy = ' + str(accuracy_rf))\n",
    "\n",
    "    model_name = \"models/rf-model\"\n",
    "    # save the model\n",
    "    !rm -rf /media/notebooks/{model_name}\n",
    "    model_rf.save(sc, model_name)\n",
    "    \n",
    "    return (labels, preds_rf)\n",
    "\n",
    "#trainRF(trainingData, maxBins, 2, 15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Bins = 52, Max Depth = 5, Num Trees = 10\n",
      "accuracy = 0.7727272727272727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.99      0.87       800\n",
      "        1.0       0.47      0.03      0.06       234\n",
      "\n",
      "avg / total       0.71      0.77      0.69      1034\n",
      "\n",
      "[[792   8]\n",
      " [227   7]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 5, Num Trees = 15\n",
      "accuracy = 0.7775628626692457\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.99      0.87       800\n",
      "        1.0       0.60      0.05      0.09       234\n",
      "\n",
      "avg / total       0.74      0.78      0.70      1034\n",
      "\n",
      "[[792   8]\n",
      " [222  12]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 5, Num Trees = 20\n",
      "accuracy = 0.7727272727272727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.99      0.87       800\n",
      "        1.0       0.47      0.03      0.06       234\n",
      "\n",
      "avg / total       0.71      0.77      0.69      1034\n",
      "\n",
      "[[791   9]\n",
      " [226   8]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 5, Num Trees = 25\n",
      "accuracy = 0.7746615087040619\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.99      0.87       800\n",
      "        1.0       0.53      0.03      0.06       234\n",
      "\n",
      "avg / total       0.72      0.77      0.69      1034\n",
      "\n",
      "[[793   7]\n",
      " [226   8]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 5, Num Trees = 30\n",
      "accuracy = 0.7756286266924565\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.99      0.87       800\n",
      "        1.0       0.54      0.06      0.10       234\n",
      "\n",
      "avg / total       0.73      0.78      0.70      1034\n",
      "\n",
      "[[789  11]\n",
      " [221  13]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 5, Num Trees = 35\n",
      "accuracy = 0.7794970986460348\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.99      0.87       800\n",
      "        1.0       0.62      0.07      0.12       234\n",
      "\n",
      "avg / total       0.75      0.78      0.70      1034\n",
      "\n",
      "[[790  10]\n",
      " [218  16]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 5, Num Trees = 40\n",
      "accuracy = 0.7717601547388782\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.99      0.87       800\n",
      "        1.0       0.42      0.02      0.04       234\n",
      "\n",
      "avg / total       0.69      0.77      0.68      1034\n",
      "\n",
      "[[793   7]\n",
      " [229   5]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 5, Num Trees = 45\n",
      "accuracy = 0.7727272727272727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.99      0.87       800\n",
      "        1.0       0.44      0.02      0.03       234\n",
      "\n",
      "avg / total       0.70      0.77      0.68      1034\n",
      "\n",
      "[[795   5]\n",
      " [230   4]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 5, Num Trees = 50\n",
      "accuracy = 0.7727272727272727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.99      0.87       800\n",
      "        1.0       0.46      0.03      0.05       234\n",
      "\n",
      "avg / total       0.71      0.77      0.68      1034\n",
      "\n",
      "[[793   7]\n",
      " [228   6]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 8, Num Trees = 10\n",
      "accuracy = 0.7736943907156673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.97      0.87       800\n",
      "        1.0       0.50      0.10      0.16       234\n",
      "\n",
      "avg / total       0.72      0.77      0.71      1034\n",
      "\n",
      "[[777  23]\n",
      " [211  23]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 8, Num Trees = 15\n",
      "accuracy = 0.776595744680851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.98      0.87       800\n",
      "        1.0       0.55      0.08      0.13       234\n",
      "\n",
      "avg / total       0.73      0.78      0.70      1034\n",
      "\n",
      "[[785  15]\n",
      " [216  18]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 8, Num Trees = 20\n",
      "accuracy = 0.7688588007736944\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.97      0.87       800\n",
      "        1.0       0.44      0.08      0.13       234\n",
      "\n",
      "avg / total       0.70      0.77      0.70      1034\n",
      "\n",
      "[[777  23]\n",
      " [216  18]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 8, Num Trees = 25\n",
      "accuracy = 0.7775628626692457\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.98      0.87       800\n",
      "        1.0       0.56      0.08      0.14       234\n",
      "\n",
      "avg / total       0.73      0.78      0.71      1034\n",
      "\n",
      "[[786  14]\n",
      " [216  18]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 8, Num Trees = 30\n",
      "accuracy = 0.7804642166344294\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.98      0.87       800\n",
      "        1.0       0.59      0.10      0.17       234\n",
      "\n",
      "avg / total       0.74      0.78      0.71      1034\n",
      "\n",
      "[[784  16]\n",
      " [211  23]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 8, Num Trees = 35\n",
      "accuracy = 0.776595744680851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.98      0.87       800\n",
      "        1.0       0.54      0.08      0.14       234\n",
      "\n",
      "avg / total       0.73      0.78      0.71      1034\n",
      "\n",
      "[[784  16]\n",
      " [215  19]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 8, Num Trees = 40\n",
      "accuracy = 0.7717601547388782\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.97      0.87       800\n",
      "        1.0       0.47      0.08      0.13       234\n",
      "\n",
      "avg / total       0.71      0.77      0.70      1034\n",
      "\n",
      "[[780  20]\n",
      " [216  18]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 8, Num Trees = 45\n",
      "accuracy = 0.7794970986460348\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.98      0.87       800\n",
      "        1.0       0.60      0.08      0.14       234\n",
      "\n",
      "avg / total       0.74      0.78      0.71      1034\n",
      "\n",
      "[[788  12]\n",
      " [216  18]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 8, Num Trees = 50\n",
      "accuracy = 0.7736943907156673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.98      0.87       800\n",
      "        1.0       0.50      0.08      0.14       234\n",
      "\n",
      "avg / total       0.72      0.77      0.70      1034\n",
      "\n",
      "[[781  19]\n",
      " [215  19]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 11, Num Trees = 10\n",
      "accuracy = 0.7756286266924565\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.95      0.87       800\n",
      "        1.0       0.51      0.18      0.27       234\n",
      "\n",
      "avg / total       0.73      0.78      0.73      1034\n",
      "\n",
      "[[759  41]\n",
      " [191  43]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 11, Num Trees = 15\n",
      "accuracy = 0.7823984526112185\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.97      0.87       800\n",
      "        1.0       0.58      0.14      0.22       234\n",
      "\n",
      "avg / total       0.75      0.78      0.73      1034\n",
      "\n",
      "[[777  23]\n",
      " [202  32]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 11, Num Trees = 20\n",
      "accuracy = 0.7640232108317214\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.95      0.86       800\n",
      "        1.0       0.42      0.11      0.18       234\n",
      "\n",
      "avg / total       0.70      0.76      0.71      1034\n",
      "\n",
      "[[764  36]\n",
      " [208  26]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 11, Num Trees = 25\n",
      "accuracy = 0.7775628626692457\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.97      0.87       800\n",
      "        1.0       0.54      0.11      0.18       234\n",
      "\n",
      "avg / total       0.73      0.78      0.71      1034\n",
      "\n",
      "[[779  21]\n",
      " [209  25]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 11, Num Trees = 30\n",
      "accuracy = 0.776595744680851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.97      0.87       800\n",
      "        1.0       0.53      0.11      0.18       234\n",
      "\n",
      "avg / total       0.73      0.78      0.72      1034\n",
      "\n",
      "[[777  23]\n",
      " [208  26]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 11, Num Trees = 35\n",
      "accuracy = 0.776595744680851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.98      0.87       800\n",
      "        1.0       0.54      0.09      0.15       234\n",
      "\n",
      "avg / total       0.73      0.78      0.71      1034\n",
      "\n",
      "[[782  18]\n",
      " [213  21]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 11, Num Trees = 40\n",
      "accuracy = 0.7785299806576402\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.97      0.87       800\n",
      "        1.0       0.55      0.11      0.19       234\n",
      "\n",
      "avg / total       0.74      0.78      0.72      1034\n",
      "\n",
      "[[779  21]\n",
      " [208  26]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 11, Num Trees = 45\n",
      "accuracy = 0.7785299806576402\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.98      0.87       800\n",
      "        1.0       0.56      0.09      0.16       234\n",
      "\n",
      "avg / total       0.74      0.78      0.71      1034\n",
      "\n",
      "[[783  17]\n",
      " [212  22]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 11, Num Trees = 50\n",
      "accuracy = 0.776595744680851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.97      0.87       800\n",
      "        1.0       0.53      0.11      0.18       234\n",
      "\n",
      "avg / total       0.73      0.78      0.71      1034\n",
      "\n",
      "[[778  22]\n",
      " [209  25]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 14, Num Trees = 10\n",
      "accuracy = 0.7611218568665378\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.93      0.86       800\n",
      "        1.0       0.43      0.17      0.24       234\n",
      "\n",
      "avg / total       0.71      0.76      0.72      1034\n",
      "\n",
      "[[747  53]\n",
      " [194  40]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 14, Num Trees = 15\n",
      "accuracy = 0.7823984526112185\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.97      0.87       800\n",
      "        1.0       0.57      0.15      0.24       234\n",
      "\n",
      "avg / total       0.75      0.78      0.73      1034\n",
      "\n",
      "[[773  27]\n",
      " [198  36]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 14, Num Trees = 20\n",
      "accuracy = 0.7688588007736944\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.95      0.86       800\n",
      "        1.0       0.46      0.14      0.21       234\n",
      "\n",
      "avg / total       0.72      0.77      0.72      1034\n",
      "\n",
      "[[763  37]\n",
      " [202  32]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 14, Num Trees = 25\n",
      "accuracy = 0.7746615087040619\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.96      0.87       800\n",
      "        1.0       0.51      0.13      0.20       234\n",
      "\n",
      "avg / total       0.73      0.77      0.72      1034\n",
      "\n",
      "[[771  29]\n",
      " [204  30]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 14, Num Trees = 30\n",
      "accuracy = 0.7688588007736944\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.96      0.86       800\n",
      "        1.0       0.46      0.13      0.20       234\n",
      "\n",
      "avg / total       0.72      0.77      0.71      1034\n",
      "\n",
      "[[765  35]\n",
      " [204  30]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 14, Num Trees = 35\n",
      "accuracy = 0.7659574468085106\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.96      0.86       800\n",
      "        1.0       0.44      0.12      0.18       234\n",
      "\n",
      "avg / total       0.71      0.77      0.71      1034\n",
      "\n",
      "[[765  35]\n",
      " [207  27]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 14, Num Trees = 40\n",
      "accuracy = 0.7736943907156673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.96      0.87       800\n",
      "        1.0       0.50      0.12      0.20       234\n",
      "\n",
      "avg / total       0.72      0.77      0.72      1034\n",
      "\n",
      "[[771  29]\n",
      " [205  29]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 14, Num Trees = 45\n",
      "accuracy = 0.7688588007736944\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.96      0.87       800\n",
      "        1.0       0.45      0.10      0.17       234\n",
      "\n",
      "avg / total       0.71      0.77      0.71      1034\n",
      "\n",
      "[[771  29]\n",
      " [210  24]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 14, Num Trees = 50\n",
      "accuracy = 0.7678916827852998\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.96      0.86       800\n",
      "        1.0       0.45      0.12      0.19       234\n",
      "\n",
      "avg / total       0.71      0.77      0.71      1034\n",
      "\n",
      "[[766  34]\n",
      " [206  28]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 17, Num Trees = 10\n",
      "accuracy = 0.7553191489361702\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.91      0.85       800\n",
      "        1.0       0.42      0.22      0.29       234\n",
      "\n",
      "avg / total       0.71      0.76      0.72      1034\n",
      "\n",
      "[[730  70]\n",
      " [183  51]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 17, Num Trees = 15\n",
      "accuracy = 0.7630560928433269\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.95      0.86       800\n",
      "        1.0       0.43      0.14      0.21       234\n",
      "\n",
      "avg / total       0.71      0.76      0.71      1034\n",
      "\n",
      "[[757  43]\n",
      " [202  32]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 17, Num Trees = 20\n",
      "accuracy = 0.7717601547388782\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.94      0.86       800\n",
      "        1.0       0.49      0.18      0.27       234\n",
      "\n",
      "avg / total       0.73      0.77      0.73      1034\n",
      "\n",
      "[[755  45]\n",
      " [191  43]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 17, Num Trees = 25\n",
      "accuracy = 0.781431334622824\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.96      0.87       800\n",
      "        1.0       0.55      0.18      0.27       234\n",
      "\n",
      "avg / total       0.74      0.78      0.73      1034\n",
      "\n",
      "[[767  33]\n",
      " [193  41]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 17, Num Trees = 30\n",
      "accuracy = 0.781431334622824\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.96      0.87       800\n",
      "        1.0       0.56      0.15      0.24       234\n",
      "\n",
      "avg / total       0.74      0.78      0.73      1034\n",
      "\n",
      "[[772  28]\n",
      " [198  36]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 17, Num Trees = 35\n",
      "accuracy = 0.7727272727272727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.95      0.87       800\n",
      "        1.0       0.49      0.15      0.23       234\n",
      "\n",
      "avg / total       0.73      0.77      0.72      1034\n",
      "\n",
      "[[763  37]\n",
      " [198  36]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 17, Num Trees = 40\n",
      "accuracy = 0.7727272727272727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.95      0.87       800\n",
      "        1.0       0.49      0.16      0.24       234\n",
      "\n",
      "avg / total       0.73      0.77      0.72      1034\n",
      "\n",
      "[[762  38]\n",
      " [197  37]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 17, Num Trees = 45\n",
      "accuracy = 0.7736943907156673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.96      0.87       800\n",
      "        1.0       0.50      0.12      0.20       234\n",
      "\n",
      "avg / total       0.72      0.77      0.72      1034\n",
      "\n",
      "[[771  29]\n",
      " [205  29]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 17, Num Trees = 50\n",
      "accuracy = 0.769825918762089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.96      0.87       800\n",
      "        1.0       0.47      0.12      0.20       234\n",
      "\n",
      "avg / total       0.72      0.77      0.71      1034\n",
      "\n",
      "[[767  33]\n",
      " [205  29]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 20, Num Trees = 10\n",
      "accuracy = 0.7543520309477756\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.91      0.85       800\n",
      "        1.0       0.42      0.24      0.30       234\n",
      "\n",
      "avg / total       0.72      0.75      0.73      1034\n",
      "\n",
      "[[725  75]\n",
      " [179  55]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 20, Num Trees = 15\n",
      "accuracy = 0.7688588007736944\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.95      0.86       800\n",
      "        1.0       0.47      0.15      0.23       234\n",
      "\n",
      "avg / total       0.72      0.77      0.72      1034\n",
      "\n",
      "[[760  40]\n",
      " [199  35]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 20, Num Trees = 20\n",
      "accuracy = 0.7640232108317214\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.94      0.86       800\n",
      "        1.0       0.45      0.18      0.25       234\n",
      "\n",
      "avg / total       0.72      0.76      0.72      1034\n",
      "\n",
      "[[749  51]\n",
      " [193  41]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 20, Num Trees = 25\n",
      "accuracy = 0.769825918762089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.94      0.86       800\n",
      "        1.0       0.48      0.18      0.27       234\n",
      "\n",
      "avg / total       0.73      0.77      0.73      1034\n",
      "\n",
      "[[753  47]\n",
      " [191  43]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 20, Num Trees = 30\n",
      "accuracy = 0.7775628626692457\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.95      0.87       800\n",
      "        1.0       0.53      0.18      0.26       234\n",
      "\n",
      "avg / total       0.74      0.78      0.73      1034\n",
      "\n",
      "[[763  37]\n",
      " [193  41]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 20, Num Trees = 35\n",
      "accuracy = 0.7794970986460348\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.96      0.87       800\n",
      "        1.0       0.54      0.16      0.25       234\n",
      "\n",
      "avg / total       0.74      0.78      0.73      1034\n",
      "\n",
      "[[769  31]\n",
      " [197  37]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 20, Num Trees = 40\n",
      "accuracy = 0.7746615087040619\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.95      0.87       800\n",
      "        1.0       0.51      0.16      0.25       234\n",
      "\n",
      "avg / total       0.73      0.77      0.73      1034\n",
      "\n",
      "[[763  37]\n",
      " [196  38]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 20, Num Trees = 45\n",
      "accuracy = 0.7785299806576402\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.97      0.87       800\n",
      "        1.0       0.54      0.14      0.22       234\n",
      "\n",
      "avg / total       0.74      0.78      0.72      1034\n",
      "\n",
      "[[773  27]\n",
      " [202  32]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 20, Num Trees = 50\n",
      "accuracy = 0.7756286266924565\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.95      0.87       800\n",
      "        1.0       0.51      0.16      0.25       234\n",
      "\n",
      "avg / total       0.73      0.78      0.73      1034\n",
      "\n",
      "[[764  36]\n",
      " [196  38]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 23, Num Trees = 10\n",
      "accuracy = 0.7543520309477756\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.90      0.85       800\n",
      "        1.0       0.43      0.25      0.31       234\n",
      "\n",
      "avg / total       0.72      0.75      0.73      1034\n",
      "\n",
      "[[722  78]\n",
      " [176  58]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 23, Num Trees = 15\n",
      "accuracy = 0.7669245647969052\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.94      0.86       800\n",
      "        1.0       0.46      0.16      0.23       234\n",
      "\n",
      "avg / total       0.72      0.77      0.72      1034\n",
      "\n",
      "[[756  44]\n",
      " [197  37]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 23, Num Trees = 20\n",
      "accuracy = 0.7630560928433269\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       800\n",
      "        1.0       0.44      0.19      0.26       234\n",
      "\n",
      "avg / total       0.72      0.76      0.72      1034\n",
      "\n",
      "[[745  55]\n",
      " [190  44]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 23, Num Trees = 25\n",
      "accuracy = 0.7688588007736944\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.95      0.86       800\n",
      "        1.0       0.46      0.14      0.21       234\n",
      "\n",
      "avg / total       0.72      0.77      0.72      1034\n",
      "\n",
      "[[763  37]\n",
      " [202  32]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 23, Num Trees = 30\n",
      "accuracy = 0.7727272727272727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.95      0.87       800\n",
      "        1.0       0.49      0.16      0.24       234\n",
      "\n",
      "avg / total       0.73      0.77      0.72      1034\n",
      "\n",
      "[[762  38]\n",
      " [197  37]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 23, Num Trees = 35\n",
      "accuracy = 0.7785299806576402\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.96      0.87       800\n",
      "        1.0       0.53      0.17      0.26       234\n",
      "\n",
      "avg / total       0.74      0.78      0.73      1034\n",
      "\n",
      "[[765  35]\n",
      " [194  40]]\n",
      "\n",
      "Max Bins = 52, Max Depth = 23, Num Trees = 40\n"
     ]
    }
   ],
   "source": [
    "for b in range(maxBins, maxBins+1):\n",
    "    for d in range(5,26,3):\n",
    "        for t in range(10,51,5):\n",
    "            print(\"Max Bins = \" + str(b) + \", Max Depth = \" + str(d) + \", Num Trees = \" + str(t))\n",
    "            (labels, preds_rf) = trainRF(trainingData, b, 2, d, t)\n",
    "            print(classification_report(labels, preds_rf))\n",
    "            print(confusion_matrix(labels, preds_rf))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullRDD = spark.read.csv(\"data/train.txt\", header=False, sep=\"\\t\").rdd\n",
    "fullDataRDD = rawRDD.map(lambda row: ([None if el is None else int(el) for el in row[1:14]] + list(row[14:]), int(row[0]))) \\\n",
    "                    .flatMap(lambda r: hashTrick(r[0], r[1], 16)) \\\n",
    "                    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLabeledRDD = fullDataRDD.map(to_labeled)\n",
    "\n",
    "# set model params\n",
    "# TODO: need this for full data\n",
    "categoricalFeaturesInfo = { int(feat[1:]) + 13: count + 2 for feat, count in num_significant_categories.items() }\n",
    "maxBins = max(num_significant_categories.values()) + 2\n",
    "fullTrainingData, fullValidationData = labeledRDD.randomSplit([0.9, 0.1])\n",
    "# re-samples the positive class\n",
    "#trainingData = trainingData.flatMap(resample)\n",
    "\n",
    "labels = fullValidationData.map(lambda lp: lp.label).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Against Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCEPTS NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bias variance tradeoff / model complexity / regularization\n",
    "One Hot Encoding / vector embeddings / feature selection\n",
    "assumptions (for different algorithms - for example OLS vs Trees)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
