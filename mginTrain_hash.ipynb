{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel, LabeledPoint, RandomForest\n",
    "\n",
    "app_name = \"w261_final_training\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawRDD = spark.read.csv(\"data/sample.txt\", header=False, sep=\"\\t\").rdd\n",
    "dataRDD = rawRDD.map(lambda row: ([None if el is None else int(el) for el in row[1:14]] + list(row[14:]), int(row[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data we saved from the EDA. This helps us engineer the features and configure the model\n",
    "\n",
    "frequent_feats = {}\n",
    "\n",
    "with open(\"data/freq_category_counts.csv\") as csvfile:\n",
    "    for row in csv.DictReader(csvfile):\n",
    "        total = int(row[\"total\"])\n",
    "        if total >= 10:\n",
    "            key = \"{}-{}\".format(row[\"col_name\"], row[\"category\"])\n",
    "            frequent_feats[key] = int(row[\"category_id\"])\n",
    "\n",
    "with open(\"data/num_significant_categories.csv\") as csvfile:\n",
    "    num_significant_categories = { row[\"field\"]: int(row[\"count\"]) for row in csv.DictReader(csvfile) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a row of features and the label\n",
    "# leave features 0-13 the same (already integers), covert and hash features \n",
    "def hashTrick(features, label, N):\n",
    "    newFeatures = list(features[0:13])\n",
    "    for i in range(14, len(features)):\n",
    "        if features[i] == None:\n",
    "            newFeatures += list([None])\n",
    "        else:\n",
    "            newFeatures += list([int(features[i], 16) % 2**N])\n",
    "    yield (newFeatures, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRDD = dataRDD.flatMap(lambda r: hashTrick(r[0], r[1], 16)).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles of Trees\n",
    "\n",
    "The numerical columns are pretty much used directly. Note that NULLs are encoded with the value -10 (also tried 0 and imputing with the medians). Categorical values are kept if they are in the common categories from the EDA. They were assigned an integer ID, which is in the frequent_feats dict. This is used to encode each value. All rare values are converted to a special ID. NULLs are converted to yet another special ID. Note that this adds 2 additional categories from the ones we picked from the EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labeled(pair):\n",
    "    \"\"\"transform input data into the features\"\"\"\n",
    "    row, label = pair\n",
    "    # collect the converted values here\n",
    "    vector = []\n",
    "    \n",
    "    for i, val in enumerate(row):\n",
    "        # if this is an numerical column\n",
    "        if i < 13:\n",
    "            if val is None:\n",
    "                val = -10\n",
    "        # if this is categorical\n",
    "        else:\n",
    "            if val is not None:\n",
    "                key = \"C{}-{}\".format(i - 13, val)\n",
    "                # if its one of our \"common\" values\n",
    "                if key in frequent_feats:\n",
    "                    # look up its ID\n",
    "                    val = frequent_feats[key]\n",
    "                else:\n",
    "                    # give it the special value for RARE\n",
    "                    val = num_significant_categories[\"C\" + str(i - 13)]\n",
    "            else:\n",
    "                # give it the special value for NULL\n",
    "                val = num_significant_categories[\"C\" + str(i - 13)] + 1\n",
    "        vector.append(val)\n",
    "    return LabeledPoint(label, vector)\n",
    "\n",
    "def resample(pair):\n",
    "    \"\"\"sample the positive examples twice to increase their importance\"\"\"\n",
    "    if pair.label == 1:\n",
    "        return [pair, pair]\n",
    "    else:\n",
    "        return [pair]\n",
    "\n",
    "labeledRDD = dataRDD.map(to_labeled)\n",
    "\n",
    "# set model params\n",
    "categoricalFeaturesInfo = { int(feat[1:]) + 13: count + 2 for feat, count in num_significant_categories.items() }\n",
    "maxBins = max(num_significant_categories.values()) + 2\n",
    "trainingData, validationData = labeledRDD.randomSplit([0.9, 0.1])\n",
    "# re-samples the positive class\n",
    "#trainingData = trainingData.flatMap(resample)\n",
    "\n",
    "labels = validationData.map(lambda lp: lp.label).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGBT(trainingData, maxBins, maxDepth, numIterations):\n",
    "\n",
    "    model_gbdt = GradientBoostedTrees.trainClassifier(trainingData,\n",
    "                                                      categoricalFeaturesInfo={},\n",
    "                                                      maxBins=maxBins,\n",
    "                                                      maxDepth=8,\n",
    "                                                      numIterations=10) # how many trees\n",
    "\n",
    "    # Evaluate model on test instances and compute validation accuracy\n",
    "    predictions_gbdt = model_gbdt.predict(validationData.map(lambda x: x.features))\n",
    "    #labelsAndPredictions = validationData.map(lambda lp: lp.label).zip(predictions)\n",
    "    #testErr = labelsAndPredictions.filter(lambda lp: lp[0] != lp[1]).count() / float(validationData.count())\n",
    "\n",
    "    preds_gbdt = predictions_gbdt.collect()\n",
    "    accuracy_gbdt = np.mean(np.array(labels) == np.array(preds_gbdt))\n",
    "    print('accuracy = ' + str(accuracy_gbdt))\n",
    "\n",
    "    model_name = \"models/gbdt-model\"\n",
    "    # save the model\n",
    "    !rm -rf /media/notebooks/{model_name}\n",
    "    model_gbdt.save(sc, model_name)\n",
    "\n",
    "    # how to load the model again, tho not necessary in this file\n",
    "    #sameModel = GradientBoostedTreesModel.load(sc, model_name)\n",
    "    #print(sameModel.toDebugString())\n",
    "    \n",
    "    return (labels, preds_gbdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth = 3, Max Bins = 10, Iterations = 5\n",
      "accuracy = 0.7691511387163561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.49      0.26      0.34       221\n",
      "\n",
      "avg / total       0.73      0.77      0.74       966\n",
      "\n",
      "[[686  59]\n",
      " [164  57]]\n",
      "\n",
      "Depth = 3, Max Bins = 10, Iterations = 9\n",
      "accuracy = 0.7691511387163561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.49      0.26      0.34       221\n",
      "\n",
      "avg / total       0.73      0.77      0.74       966\n",
      "\n",
      "[[686  59]\n",
      " [164  57]]\n",
      "\n",
      "Depth = 3, Max Bins = 15, Iterations = 5\n",
      "accuracy = 0.7484472049689441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.38      0.15      0.22       221\n",
      "\n",
      "avg / total       0.69      0.75      0.71       966\n",
      "\n",
      "[[689  56]\n",
      " [187  34]]\n",
      "\n",
      "Depth = 3, Max Bins = 15, Iterations = 9\n",
      "accuracy = 0.7484472049689441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.38      0.15      0.22       221\n",
      "\n",
      "avg / total       0.69      0.75      0.71       966\n",
      "\n",
      "[[689  56]\n",
      " [187  34]]\n",
      "\n",
      "Depth = 3, Max Bins = 20, Iterations = 5\n",
      "accuracy = 0.7536231884057971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.42      0.19      0.26       221\n",
      "\n",
      "avg / total       0.71      0.75      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [179  42]]\n",
      "\n",
      "Depth = 3, Max Bins = 20, Iterations = 9\n",
      "accuracy = 0.7536231884057971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.42      0.19      0.26       221\n",
      "\n",
      "avg / total       0.71      0.75      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [179  42]]\n",
      "\n",
      "Depth = 3, Max Bins = 25, Iterations = 5\n",
      "accuracy = 0.7732919254658385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.51      0.26      0.35       221\n",
      "\n",
      "avg / total       0.74      0.77      0.74       966\n",
      "\n",
      "[[689  56]\n",
      " [163  58]]\n",
      "\n",
      "Depth = 3, Max Bins = 25, Iterations = 9\n",
      "accuracy = 0.7732919254658385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.51      0.26      0.35       221\n",
      "\n",
      "avg / total       0.74      0.77      0.74       966\n",
      "\n",
      "[[689  56]\n",
      " [163  58]]\n",
      "\n",
      "Depth = 3, Max Bins = 30, Iterations = 5\n",
      "accuracy = 0.7463768115942029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.85       745\n",
      "        1.0       0.40      0.21      0.27       221\n",
      "\n",
      "avg / total       0.70      0.75      0.72       966\n",
      "\n",
      "[[675  70]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 3, Max Bins = 30, Iterations = 9\n",
      "accuracy = 0.7463768115942029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.85       745\n",
      "        1.0       0.40      0.21      0.27       221\n",
      "\n",
      "avg / total       0.70      0.75      0.72       966\n",
      "\n",
      "[[675  70]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 3, Max Bins = 35, Iterations = 5\n",
      "accuracy = 0.7567287784679089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.22      0.29       221\n",
      "\n",
      "avg / total       0.72      0.76      0.72       966\n",
      "\n",
      "[[683  62]\n",
      " [173  48]]\n",
      "\n",
      "Depth = 3, Max Bins = 35, Iterations = 9\n",
      "accuracy = 0.7567287784679089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.22      0.29       221\n",
      "\n",
      "avg / total       0.72      0.76      0.72       966\n",
      "\n",
      "[[683  62]\n",
      " [173  48]]\n",
      "\n",
      "Depth = 3, Max Bins = 40, Iterations = 5\n",
      "accuracy = 0.7556935817805382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.43      0.20      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[685  60]\n",
      " [176  45]]\n",
      "\n",
      "Depth = 3, Max Bins = 40, Iterations = 9\n",
      "accuracy = 0.7556935817805382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.43      0.20      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[685  60]\n",
      " [176  45]]\n",
      "\n",
      "Depth = 3, Max Bins = 45, Iterations = 5\n",
      "accuracy = 0.7598343685300207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       745\n",
      "        1.0       0.44      0.19      0.27       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[691  54]\n",
      " [178  43]]\n",
      "\n",
      "Depth = 3, Max Bins = 45, Iterations = 9\n",
      "accuracy = 0.7598343685300207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       745\n",
      "        1.0       0.44      0.19      0.27       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[691  54]\n",
      " [178  43]]\n",
      "\n",
      "Depth = 3, Max Bins = 50, Iterations = 5\n",
      "accuracy = 0.7577639751552795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.21      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 3, Max Bins = 50, Iterations = 9\n",
      "accuracy = 0.7577639751552795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.21      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 6, Max Bins = 10, Iterations = 5\n",
      "accuracy = 0.7691511387163561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.49      0.26      0.34       221\n",
      "\n",
      "avg / total       0.73      0.77      0.74       966\n",
      "\n",
      "[[686  59]\n",
      " [164  57]]\n",
      "\n",
      "Depth = 6, Max Bins = 10, Iterations = 9\n",
      "accuracy = 0.7691511387163561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.49      0.26      0.34       221\n",
      "\n",
      "avg / total       0.73      0.77      0.74       966\n",
      "\n",
      "[[686  59]\n",
      " [164  57]]\n",
      "\n",
      "Depth = 6, Max Bins = 15, Iterations = 5\n",
      "accuracy = 0.7484472049689441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.38      0.15      0.22       221\n",
      "\n",
      "avg / total       0.69      0.75      0.71       966\n",
      "\n",
      "[[689  56]\n",
      " [187  34]]\n",
      "\n",
      "Depth = 6, Max Bins = 15, Iterations = 9\n",
      "accuracy = 0.7484472049689441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.38      0.15      0.22       221\n",
      "\n",
      "avg / total       0.69      0.75      0.71       966\n",
      "\n",
      "[[689  56]\n",
      " [187  34]]\n",
      "\n",
      "Depth = 6, Max Bins = 20, Iterations = 5\n",
      "accuracy = 0.7536231884057971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.42      0.19      0.26       221\n",
      "\n",
      "avg / total       0.71      0.75      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [179  42]]\n",
      "\n",
      "Depth = 6, Max Bins = 20, Iterations = 9\n",
      "accuracy = 0.7536231884057971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.42      0.19      0.26       221\n",
      "\n",
      "avg / total       0.71      0.75      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [179  42]]\n",
      "\n",
      "Depth = 6, Max Bins = 25, Iterations = 5\n",
      "accuracy = 0.7732919254658385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.51      0.26      0.35       221\n",
      "\n",
      "avg / total       0.74      0.77      0.74       966\n",
      "\n",
      "[[689  56]\n",
      " [163  58]]\n",
      "\n",
      "Depth = 6, Max Bins = 25, Iterations = 9\n",
      "accuracy = 0.7732919254658385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.51      0.26      0.35       221\n",
      "\n",
      "avg / total       0.74      0.77      0.74       966\n",
      "\n",
      "[[689  56]\n",
      " [163  58]]\n",
      "\n",
      "Depth = 6, Max Bins = 30, Iterations = 5\n",
      "accuracy = 0.7463768115942029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.85       745\n",
      "        1.0       0.40      0.21      0.27       221\n",
      "\n",
      "avg / total       0.70      0.75      0.72       966\n",
      "\n",
      "[[675  70]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 6, Max Bins = 30, Iterations = 9\n",
      "accuracy = 0.7463768115942029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.85       745\n",
      "        1.0       0.40      0.21      0.27       221\n",
      "\n",
      "avg / total       0.70      0.75      0.72       966\n",
      "\n",
      "[[675  70]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 6, Max Bins = 35, Iterations = 5\n",
      "accuracy = 0.7567287784679089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.22      0.29       221\n",
      "\n",
      "avg / total       0.72      0.76      0.72       966\n",
      "\n",
      "[[683  62]\n",
      " [173  48]]\n",
      "\n",
      "Depth = 6, Max Bins = 35, Iterations = 9\n",
      "accuracy = 0.7567287784679089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.22      0.29       221\n",
      "\n",
      "avg / total       0.72      0.76      0.72       966\n",
      "\n",
      "[[683  62]\n",
      " [173  48]]\n",
      "\n",
      "Depth = 6, Max Bins = 40, Iterations = 5\n",
      "accuracy = 0.7556935817805382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.43      0.20      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[685  60]\n",
      " [176  45]]\n",
      "\n",
      "Depth = 6, Max Bins = 40, Iterations = 9\n",
      "accuracy = 0.7556935817805382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.43      0.20      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[685  60]\n",
      " [176  45]]\n",
      "\n",
      "Depth = 6, Max Bins = 45, Iterations = 5\n",
      "accuracy = 0.7598343685300207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       745\n",
      "        1.0       0.44      0.19      0.27       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[691  54]\n",
      " [178  43]]\n",
      "\n",
      "Depth = 6, Max Bins = 45, Iterations = 9\n",
      "accuracy = 0.7598343685300207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       745\n",
      "        1.0       0.44      0.19      0.27       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[691  54]\n",
      " [178  43]]\n",
      "\n",
      "Depth = 6, Max Bins = 50, Iterations = 5\n",
      "accuracy = 0.7577639751552795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.21      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 6, Max Bins = 50, Iterations = 9\n",
      "accuracy = 0.7577639751552795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.21      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 9, Max Bins = 10, Iterations = 5\n",
      "accuracy = 0.7691511387163561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.49      0.26      0.34       221\n",
      "\n",
      "avg / total       0.73      0.77      0.74       966\n",
      "\n",
      "[[686  59]\n",
      " [164  57]]\n",
      "\n",
      "Depth = 9, Max Bins = 10, Iterations = 9\n",
      "accuracy = 0.7691511387163561\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.49      0.26      0.34       221\n",
      "\n",
      "avg / total       0.73      0.77      0.74       966\n",
      "\n",
      "[[686  59]\n",
      " [164  57]]\n",
      "\n",
      "Depth = 9, Max Bins = 15, Iterations = 5\n",
      "accuracy = 0.7484472049689441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.38      0.15      0.22       221\n",
      "\n",
      "avg / total       0.69      0.75      0.71       966\n",
      "\n",
      "[[689  56]\n",
      " [187  34]]\n",
      "\n",
      "Depth = 9, Max Bins = 15, Iterations = 9\n",
      "accuracy = 0.7484472049689441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.38      0.15      0.22       221\n",
      "\n",
      "avg / total       0.69      0.75      0.71       966\n",
      "\n",
      "[[689  56]\n",
      " [187  34]]\n",
      "\n",
      "Depth = 9, Max Bins = 20, Iterations = 5\n",
      "accuracy = 0.7536231884057971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.42      0.19      0.26       221\n",
      "\n",
      "avg / total       0.71      0.75      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [179  42]]\n",
      "\n",
      "Depth = 9, Max Bins = 20, Iterations = 9\n",
      "accuracy = 0.7536231884057971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.92      0.85       745\n",
      "        1.0       0.42      0.19      0.26       221\n",
      "\n",
      "avg / total       0.71      0.75      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [179  42]]\n",
      "\n",
      "Depth = 9, Max Bins = 25, Iterations = 5\n",
      "accuracy = 0.7732919254658385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.51      0.26      0.35       221\n",
      "\n",
      "avg / total       0.74      0.77      0.74       966\n",
      "\n",
      "[[689  56]\n",
      " [163  58]]\n",
      "\n",
      "Depth = 9, Max Bins = 25, Iterations = 9\n",
      "accuracy = 0.7732919254658385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.92      0.86       745\n",
      "        1.0       0.51      0.26      0.35       221\n",
      "\n",
      "avg / total       0.74      0.77      0.74       966\n",
      "\n",
      "[[689  56]\n",
      " [163  58]]\n",
      "\n",
      "Depth = 9, Max Bins = 30, Iterations = 5\n",
      "accuracy = 0.7463768115942029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.85       745\n",
      "        1.0       0.40      0.21      0.27       221\n",
      "\n",
      "avg / total       0.70      0.75      0.72       966\n",
      "\n",
      "[[675  70]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 9, Max Bins = 30, Iterations = 9\n",
      "accuracy = 0.7463768115942029\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.85       745\n",
      "        1.0       0.40      0.21      0.27       221\n",
      "\n",
      "avg / total       0.70      0.75      0.72       966\n",
      "\n",
      "[[675  70]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 9, Max Bins = 35, Iterations = 5\n",
      "accuracy = 0.7567287784679089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.22      0.29       221\n",
      "\n",
      "avg / total       0.72      0.76      0.72       966\n",
      "\n",
      "[[683  62]\n",
      " [173  48]]\n",
      "\n",
      "Depth = 9, Max Bins = 35, Iterations = 9\n",
      "accuracy = 0.7567287784679089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.22      0.29       221\n",
      "\n",
      "avg / total       0.72      0.76      0.72       966\n",
      "\n",
      "[[683  62]\n",
      " [173  48]]\n",
      "\n",
      "Depth = 9, Max Bins = 40, Iterations = 5\n",
      "accuracy = 0.7556935817805382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.43      0.20      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[685  60]\n",
      " [176  45]]\n",
      "\n",
      "Depth = 9, Max Bins = 40, Iterations = 9\n",
      "accuracy = 0.7556935817805382\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.43      0.20      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[685  60]\n",
      " [176  45]]\n",
      "\n",
      "Depth = 9, Max Bins = 45, Iterations = 5\n",
      "accuracy = 0.7598343685300207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       745\n",
      "        1.0       0.44      0.19      0.27       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[691  54]\n",
      " [178  43]]\n",
      "\n",
      "Depth = 9, Max Bins = 45, Iterations = 9\n",
      "accuracy = 0.7598343685300207\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86       745\n",
      "        1.0       0.44      0.19      0.27       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[691  54]\n",
      " [178  43]]\n",
      "\n",
      "Depth = 9, Max Bins = 50, Iterations = 5\n",
      "accuracy = 0.7577639751552795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.21      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [175  46]]\n",
      "\n",
      "Depth = 9, Max Bins = 50, Iterations = 9\n",
      "accuracy = 0.7577639751552795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.92      0.85       745\n",
      "        1.0       0.44      0.21      0.28       221\n",
      "\n",
      "avg / total       0.71      0.76      0.72       966\n",
      "\n",
      "[[686  59]\n",
      " [175  46]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loop through various combinations of tree depth, bins, and iterations\n",
    "# this will help us hone in on which parameters to use for our final model\n",
    "for td in range(3,12,3):\n",
    "    for b in range(10, maxBins,5):\n",
    "        for i in range(5,12,4):\n",
    "            print(\"Depth = \" + str(td) + \", Max Bins = \" + str(b) + \", Iterations = \" + str(i))\n",
    "            (labels, preds_gbdt) = trainGBT(trainingData, b, td, i)\n",
    "            print(classification_report(labels, preds_gbdt))\n",
    "            print(confusion_matrix(labels, preds_gbdt))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainRF(trainingData, maxBins, numClasses, maxDepth, numTrees):\n",
    "    model_rf = RandomForest.trainClassifier(trainingData,\n",
    "                                        categoricalFeaturesInfo=categoricalFeaturesInfo,\n",
    "                                        maxBins=maxBins,\n",
    "                                        numClasses=numClasses,\n",
    "                                        maxDepth=15,\n",
    "                                        numTrees=10)\n",
    "\n",
    "    # Evaluate model on test instances and compute validation accuracy\n",
    "    predictions_rf = model_rf.predict(validationData.map(lambda x: x.features))\n",
    "\n",
    "    preds_rf = predictions_rf.collect()\n",
    "    accuracy_rf = np.mean(np.array(labels) == np.array(preds_rf))\n",
    "    print('accuracy = ' + str(accuracy_rf))\n",
    "\n",
    "    model_name = \"models/rf-model\"\n",
    "    # save the model\n",
    "    !rm -rf /media/notebooks/{model_name}\n",
    "    model_rf.save(sc, model_name)\n",
    "    \n",
    "    return (labels, preds_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(2, maxBins,3):\n",
    "    for d in range(5,16,3):\n",
    "        for t in range(5,20,3):\n",
    "            print(\"Max Bins = \" + str(b) + \", Max Depth = \" + str(d) + \", Num Trees = \" + str(t))\n",
    "            (labels, preds_rf) = trainRF(trainingData, b, 2, d, t)\n",
    "            print(classification_report(labels, preds_rf))\n",
    "            print(confusion_matrix(labels, preds_rf))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullRDD = spark.read.csv(\"data/train.txt\", header=False, sep=\"\\t\").rdd\n",
    "fullDataRDD = rawRDD.map(lambda row: ([None if el is None else int(el) for el in row[1:14]] + list(row[14:]), int(row[0]))) \\\n",
    "                    .flatMap(lambda r: hashTrick(r[0], r[1], 16)) \\\n",
    "                    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLabeledRDD = fullDataRDD.map(to_labeled)\n",
    "\n",
    "# set model params\n",
    "# TODO: need this for full data\n",
    "categoricalFeaturesInfo = { int(feat[1:]) + 13: count + 2 for feat, count in num_significant_categories.items() }\n",
    "maxBins = max(num_significant_categories.values()) + 2\n",
    "fullTrainingData, fullValidationData = labeledRDD.randomSplit([0.9, 0.1])\n",
    "# re-samples the positive class\n",
    "#trainingData = trainingData.flatMap(resample)\n",
    "\n",
    "labels = fullValidationData.map(lambda lp: lp.label).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Against Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
