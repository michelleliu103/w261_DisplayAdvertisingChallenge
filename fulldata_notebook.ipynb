{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592a71a6c7bb4266878bd3139b18605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1544511107199_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-32-184.ec2.internal:20888/proxy/application_1544511107199_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-39-171.ec2.internal:8042/node/containerlogs/container_1544511107199_0001_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel, LabeledPoint, RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8e46d775e146d5a45266fa1befa679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"w261_final_project_full_cluster\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347a44833c7c4f00bced23ee699b58fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_rawRDD =  spark.read.csv(\"s3://w261-final-project/train.txt\", sep=\"\\t\").rdd\n",
    "full_dataRDD = full_rawRDD.map(lambda row: ([None if el is None else int(el) for el in row[1:14]] \\\n",
    "                                  + list(row[14:]), int(row[0]))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d830d85ee71346768859ab7ebb487a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the data we saved from the EDA. This helps us engineer the features and configure the model\n",
    "frequent_feats = {}\n",
    "freq_category_counts = spark.read.csv(\"s3://w261-final-project/e-8PURQZJJLNHJVCFY18HE4Z2P/data/freq_category_counts.csv\", \\\n",
    "                                       header=True, sep=\",\").rdd.map(lambda row: row.asDict()).collect()\n",
    "for row in freq_category_counts:\n",
    "    total = int(row[\"total\"])\n",
    "    if total >= 10:\n",
    "        key = \"{}-{}\".format(row[\"col_name\"], row[\"category\"])\n",
    "        frequent_feats[key] = int(row[\"category_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c9ec176c8c46db9910ab5dc58998f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 42310)\n",
      "----------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.4/socketserver.py\", line 305, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib64/python3.4/socketserver.py\", line 331, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib64/python3.4/socketserver.py\", line 344, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib64/python3.4/socketserver.py\", line 673, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 263, in handle\n",
      "    poll(authenticate_and_accum_updates)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 238, in poll\n",
      "    if func():\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 251, in authenticate_and_accum_updates\n",
      "    received_token = self.rfile.read(len(auth_token))\n",
      "TypeError: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "num_significant_dict =  spark.read.csv(\"s3://w261-final-project/e-8PURQZJJLNHJVCFY18HE4Z2P/data/num_significant_categories.csv\",\\\n",
    "                                            header=True, sep=\",\").rdd.map(lambda row: row.asDict()).collect()\n",
    "\n",
    "num_significant_categories = { row[\"field\"]: int(row[\"count\"]) for row in num_significant_dict }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029234d6fcf44148b9c548e329c7a038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'field': 'C13', 'count': '26'}, {'field': 'C2', 'count': '50'}, {'field': 'C20', 'count': '50'}, {'field': 'C1', 'count': '50'}, {'field': 'C18', 'count': '50'}, {'field': 'C23', 'count': '50'}, {'field': 'C21', 'count': '17'}, {'field': 'C14', 'count': '50'}, {'field': 'C8', 'count': '3'}, {'field': 'C6', 'count': '50'}, {'field': 'C15', 'count': '50'}, {'field': 'C9', 'count': '50'}, {'field': 'C3', 'count': '50'}, {'field': 'C24', 'count': '50'}, {'field': 'C17', 'count': '50'}, {'field': 'C22', 'count': '15'}, {'field': 'C16', 'count': '10'}, {'field': 'C11', 'count': '50'}, {'field': 'C7', 'count': '50'}, {'field': 'C4', 'count': '50'}, {'field': 'C5', 'count': '18'}, {'field': 'C0', 'count': '50'}, {'field': 'C25', 'count': '50'}, {'field': 'C10', 'count': '50'}, {'field': 'C19', 'count': '4'}, {'field': 'C12', 'count': '50'}]"
     ]
    }
   ],
   "source": [
    "num_significant_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046e4773d76541f6b8e2e388437f0db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_labeled(pair):\n",
    "    \"\"\"transform input data into the features\"\"\"\n",
    "    row, label = pair\n",
    "    # collect the converted values here\n",
    "    vector = []\n",
    "    \n",
    "    for i, val in enumerate(row):\n",
    "        # if this is an numerical column\n",
    "        if i < 13:\n",
    "            if val is None:\n",
    "                val = -10\n",
    "        # if this is categorical\n",
    "        else:\n",
    "            if val is not None:\n",
    "                key = \"C{}-{}\".format(i - 13, val)\n",
    "                # if its one of our \"common\" values\n",
    "                if key in frequent_feats:\n",
    "                    # look up its ID\n",
    "                    val = frequent_feats[key]\n",
    "                else:\n",
    "                    # give it the special value for RARE\n",
    "                    val = num_significant_categories[\"C\" + str(i - 13)]\n",
    "            else:\n",
    "                # give it the special value for NULL\n",
    "                val = num_significant_categories[\"C\" + str(i - 13)] + 1\n",
    "        vector.append(val)\n",
    "    return LabeledPoint(label, vector)\n",
    "\n",
    "def resample(pair):\n",
    "    \"\"\"sample the positive examples twice to increase their importance\"\"\"\n",
    "    if pair.label == 1:\n",
    "        return [pair, pair]\n",
    "    else:\n",
    "        return [pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5c6f11247f4dafa93452eecf368887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# define the hash trick to convert string features to numeric and reduce the feature space\n",
    "# take a row of features and the label\n",
    "# leave features 0-13 the same (already integers), convert and hash features \n",
    "def hashTrick(features, label, N):\n",
    "    newFeatures = list(features[0:13])\n",
    "    for i in range(14, len(features)):\n",
    "        if features[i] == None:\n",
    "            newFeatures += list([None])\n",
    "        else:\n",
    "            newFeatures += list([int(features[i], 16) % 2**N])\n",
    "    yield (newFeatures, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046f572e2fd0456bb9b0726eb1367f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[42] at RDD at PythonRDD.scala:52"
     ]
    }
   ],
   "source": [
    "full_dataRDD.flatMap(lambda r: hashTrick(r[0], r[1], 16)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2463aeeb5a224ef38d06b047eda48780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fullLabeledRDD = full_dataRDD.map(to_labeled)\n",
    "\n",
    "# set model params\n",
    "categoricalFeaturesInfo = { int(feat[1:]) + 13: count + 2 for feat, count in num_significant_categories.items() }\n",
    "fullTrainingData, fullValidationData = fullLabeledRDD.randomSplit([0.9, 0.1])\n",
    "fullLabels = fullValidationData.map(lambda lp: lp.label).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77c98e30c39489787b6a9294558273e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_model_rf = RandomForest.trainClassifier(fullTrainingData,\n",
    "                                        categoricalFeaturesInfo={},\n",
    "                                        maxBins=52,\n",
    "                                        numClasses=2,\n",
    "                                        maxDepth=15,\n",
    "                                        numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5203f7c80c542f282bf5ab52ab60e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7675660793071678"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test instances and compute validation accuracy\n",
    "final_predictions_rf = final_model_rf.predict(fullValidationData.map(lambda x: x.features))\n",
    "final_preds_rf = final_predictions_rf.collect()\n",
    "final_accuracy_rf = np.mean(np.array(fullLabels) == np.array(final_preds_rf))\n",
    "print('accuracy = ' + str(final_accuracy_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf40a015132469aa78b7740bc36f006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.96      0.86   3408223\n",
      "         1.0       0.64      0.21      0.32   1175398\n",
      "\n",
      "   micro avg       0.77      0.77      0.77   4583621\n",
      "   macro avg       0.71      0.59      0.59   4583621\n",
      "weighted avg       0.74      0.77      0.72   4583621\n",
      "\n",
      "[[3267465  140758]\n",
      " [ 924631  250767]]"
     ]
    }
   ],
   "source": [
    "print(classification_report(fullLabels, final_preds_rf))\n",
    "print(confusion_matrix(fullLabels, final_preds_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
